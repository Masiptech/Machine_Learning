{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying News Articles with K-Nearest Neighbor Model\n",
    "\n",
    "The 20 Newsgroups dataset collects 20,000 newsgroup documents, partitioned into 20 groups. It has become a popular dataset to demo text classification and clustering. This exercise might seems difficult at first, especially for those you have not studied text processing, but you will eventually get it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "First let's load 20newsgroup data which contain newsletter articles + news categorical labels. We picked 5 news group to to this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['comp.graphics', 'rec.motorcycles', 'sci.space', 'talk.politics.mideast', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.graphics', 'rec.motorcycles', 'sci.space', 'talk.politics.mideast', 'talk.religion.misc']\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your dataset is organized in a dictionary format, with the following attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are numerical code of news categories. Their labels are also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 4, 3, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'rec.motorcycles',\n",
       " 'sci.space',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the number of news articles included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4524"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: James Leo Belliveau <jbc9+@andrew.cmu.edu>\n",
      "Subject: First Bike??\n",
      "Organization: Freshman, Mechanical Engineering, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 17\n",
      "NNTP-Posting-Host: po2.andrew.cmu.edu\n",
      "\n",
      " Anyone, \n",
      "\n",
      "    I am a serious motorcycle enthusiast without a motorcycle, and to\n",
      "put it bluntly, it sucks.  I really would like some advice on what would\n",
      "be a good starter bike for me.  I do know one thing however, I need to\n",
      "make my first bike a good one, because buying a second any time soon is\n",
      "out of the question.  I am specifically interested in racing bikes, (CBR\n",
      "600 F2, GSX-R 750).  I know that this may sound kind of crazy\n",
      "considering that I've never had a bike before, but I am responsible, a\n",
      "fast learner, and in love.  Please give me any advice that you think\n",
      "would help me in my search, including places to look or even specific\n",
      "bikes that you want to sell me.\n",
      "\n",
      "    Thanks  :-)\n",
      "\n",
      "    Jamie Belliveau (jbc9@andrew.cmu.edu)  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text feature preprocessing\n",
    "\n",
    "#### A little bit of background on how to go from text to feature\n",
    "\n",
    "\n",
    "Our first task is to change from text to numerical feature vectors. You do not have to be too concerned about this, we have done this step for you. For those of you who wants to understand the background of this transformation, you can read about it below. Feel free to shoot us any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency\n",
    "\n",
    "We want to transform text to vector first. The easiest thing is to count the number of words in the document.\n",
    "\n",
    "Suppose this is our document d:\n",
    "\n",
    "\"The dog is chasing another dog.\"\n",
    "\n",
    "We would like to transform it to a vector:\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{6} & \\frac{1}{3} & \\frac{1}{6} & \\frac{1}{6} & \\frac{1}{6}\n",
    "\\end{bmatrix}\n",
    "\n",
    "which corresponds to term frequencies of:\n",
    "\\begin{bmatrix}\n",
    "the & dog & is & chasing & another\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequencies vector is the \"feature vector\" of a document in our machine learning problem.\n",
    "\n",
    "The frequency of term $t$ in document $d$ is defined as the following:\n",
    "\n",
    "$$tf(t,d) = \\frac{\\text{The number of term t in document d}}{\\text{the number of all words in document d}}$$\n",
    "\n",
    "Often, we use logarithmic scaled $tf$ with the following definition:\n",
    "\n",
    "$$tf_{scaled}(t,d) = 1+log(tf(t,d))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Document Frequency\n",
    "\n",
    "Now you can imagine that the frequencies of common words like \"the\" or \"and\" are going to be really high, even though the frequency of these words do not tell us anything about the gist of the document. So people often use another word frequency measure called \"inverse document frequency\" or \"idf\". This is the ratio of the number of documents we have and the number of documents with the term t in it. \n",
    "\n",
    "$$idf(t) = \\frac{\\text{the number of documents}}{\\text{the number of documents that contain term t}}$$\n",
    "\n",
    "Usually, $idf$ is also transformed by logarithmic scaling:\n",
    "\n",
    "$$idf_{scaled}(t) = log(1+idf(t))$$\t\n",
    "\n",
    "If a lot of documents contain term $t$, idf will be low, meaning that term is not important. If only a few documents contain term $t$, idf will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf\n",
    "\n",
    "In practice, we often use $tf$ and $idf$ together. So the each feature in the vector is a product of the two measures.\n",
    "\n",
    "$$tfidf(t,d) = tf(t,d) \\cdot idf(t)$$\t\n",
    "\n",
    "\n",
    "If a terms has high $tfidf$, it means that small number of documents have this term and the term has high frequency when it appears. Together this filters out common terms from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides a module for calculating this, this is called TfidfVectorizer. We are going to create a TfidfVectorizer object and use function `fit` and `fit_transform` to generate the right input vector for our classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=2500, stop_words='english', use_idf=True)\n",
    "x = vectorizer.fit_transform(dataset.data)\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Initiate KNN classifier and fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the accuracy of the classification\n",
    "\n",
    "If you want to try something new, use `sklearn.metrics.classification_report` to test your classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Try changing n_neighbors parameter or other parameters to see what's the best setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Try comparing KNN model with, say MLPClassifier and LogisticRegression. Which one performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
